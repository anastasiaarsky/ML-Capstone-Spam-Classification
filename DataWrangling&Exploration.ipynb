{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anastasiaarsky/ML_Capstone/blob/main/DataWrangling%26Exploration.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "1a07e7ce",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1a07e7ce",
        "outputId": "2cb6dc52-6cb0-4768-92ec-e2d84b429c72"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "import glob\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import string\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2MDK5sPnqGxQ",
        "outputId": "494a2a59-2e5d-467c-e0c5-bf281dcef58a"
      },
      "id": "2MDK5sPnqGxQ",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_PATH = \"/content/drive/My Drive/UCSD Machine Learning Engineering Bootcamp/Capstone Project/\""
      ],
      "metadata": {
        "id": "gQUOWhY7BVKw"
      },
      "id": "gQUOWhY7BVKw",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "314cbcef",
      "metadata": {
        "id": "314cbcef"
      },
      "outputs": [],
      "source": [
        "# Load data to CSV\n",
        "df = pd.read_csv('Data.csv')\n",
        "#fdf = pd.read_csv('Full_data.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "62b27a3d",
      "metadata": {
        "id": "62b27a3d"
      },
      "source": [
        "## Text Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "4af06fdf",
      "metadata": {
        "id": "4af06fdf"
      },
      "outputs": [],
      "source": [
        "# Combine Subject and Message into Full Text\n",
        "df['Full_Text'] = df[\"Subject\"].map(str) + '. ' + df[\"Message\"].map(str)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# takes a df column and returns a normalized list of strings\n",
        "# (each string in the list represents one email/sample)\n",
        "#\n",
        "# Normalization process:\n",
        "# transforms each token to lower case, converts URLs to the string 'URL',\n",
        "# converts emails to the string 'email', converts numbers to the string 'number',\n",
        "# and removes extra newlines, whitespace, and stopwords\n",
        "def normalize_corpus(col):\n",
        "    norm_corpus = []\n",
        "    for text in col:\n",
        "      text = re.sub(r'https?:\\/\\/(www\\.)?[-a-zA-Z0-9@:%._\\+~#=]{1,256}\\.[a-zA-Z0-9()]{1,6}\\b([-a-zA-Z0-9()@:%_\\+.~#?&//=]*)', 'URL', text)\n",
        "      text = re.sub(r'<\\S+@\\S+>', 'email', text)\n",
        "      text = re.sub(r'[0-9]+','number', text)\n",
        "      text = text.lower()\n",
        "      text = re.sub(r'[\\r|\\n|\\r\\n]+', ' ', text)\n",
        "      text = re.sub(r' +', ' ', text)\n",
        "      words = text.split()\n",
        "      # words = [word.strip(string.punctuation) for word in words]\n",
        "      text = ' '.join([word for word in words if len(word) > 0 if word not in set(stopwords.words())])\n",
        "      norm_corpus.append(text)\n",
        "    return norm_corpus"
      ],
      "metadata": {
        "id": "pBqRBN4IPk-_"
      },
      "id": "pBqRBN4IPk-_",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pre-process Full Text column in grou[s] and save as Clean Text\n",
        "\n",
        "# preprocess_data takes an index number and df and returns a cleaned version of\n",
        "# the df\n",
        "# also keeps track of the execution time\n",
        "def preprocess_data(index, group):\n",
        "  start_time = time.time()\n",
        "  group['Clean_Text'] = normalize_corpus(group['Full_Text'])\n",
        "  print(\"Execution time for Group %d: %.3f ms\" % (index, time.time() - start_time))\n",
        "  return group\n",
        "\n",
        "# split df into twenty groups\n",
        "df_split = np.array_split(df, 10)"
      ],
      "metadata": {
        "id": "PEXTda9qPOl8"
      },
      "id": "PEXTda9qPOl8",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# call preprocess_data on group 1\n",
        "group1 = preprocess_data(1, df_split[0])\n",
        "group1.to_csv(DATA_PATH + 'Groups/Group1.csv', index=False)"
      ],
      "metadata": {
        "id": "ZsDe-NVDBBNh"
      },
      "id": "ZsDe-NVDBBNh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# call preprocess_data on group 2\n",
        "group2 = preprocess_data(2, df_split[1])\n",
        "group2.to_csv(DATA_PATH + 'Groups/Group2.csv', index=False)"
      ],
      "metadata": {
        "id": "5TkbJeGKBBW0"
      },
      "id": "5TkbJeGKBBW0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# call preprocess_data on group 3\n",
        "group3 = preprocess_data(3, df_split[2])\n",
        "group3.to_csv(DATA_PATH + 'Groups/Group3.csv', index=False)"
      ],
      "metadata": {
        "id": "Sk1r5ygRBBfC"
      },
      "id": "Sk1r5ygRBBfC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# call preprocess_data on group 4\n",
        "group4 = preprocess_data(4, df_split[3])\n",
        "group4.to_csv(DATA_PATH + 'Groups/Group4.csv', index=False)"
      ],
      "metadata": {
        "id": "0Ngr7WKBBBm_"
      },
      "id": "0Ngr7WKBBBm_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# call preprocess_data on group 5\n",
        "group5 = preprocess_data(5, df_split[4])\n",
        "group5.to_csv(DATA_PATH + 'Groups/Group5.csv', index=False)"
      ],
      "metadata": {
        "id": "zzqFhec4BBux"
      },
      "id": "zzqFhec4BBux",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# call preprocess_data on group 6\n",
        "group6 = preprocess_data(6, df_split[5])\n",
        "group6.to_csv(DATA_PATH + 'Groups/Group6.csv', index=False)"
      ],
      "metadata": {
        "id": "qOXU-CTmBB2j"
      },
      "id": "qOXU-CTmBB2j",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# call preprocess_data on group 7\n",
        "group7 = preprocess_data(7, df_split[6])\n",
        "group7.to_csv(DATA_PATH + 'Groups/Group7.csv', index=False)"
      ],
      "metadata": {
        "id": "q0bZrphZBB_8"
      },
      "id": "q0bZrphZBB_8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# call preprocess_data on group 8\n",
        "group8 = preprocess_data(8, df_split[7])\n",
        "group8.to_csv(DATA_PATH + 'Groups/Group8.csv', index=False)"
      ],
      "metadata": {
        "id": "-V33idP6BCIj"
      },
      "id": "-V33idP6BCIj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# call preprocess_data on group 9\n",
        "group9 = preprocess_data(9, df_split[8])\n",
        "group9.to_csv(DATA_PATH + 'Groups/Group9.csv', index=False)"
      ],
      "metadata": {
        "id": "QfXWqavsBCRY"
      },
      "id": "QfXWqavsBCRY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# call preprocess_data on group 10\n",
        "group10 = preprocess_data(10, df_split[9])\n",
        "group10.to_csv(DATA_PATH + 'Groups/Group10.csv', index=False)"
      ],
      "metadata": {
        "id": "cauoyD5mB4q4"
      },
      "id": "cauoyD5mB4q4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# concatenate all the groups into clean_df\n",
        "\n",
        "# Get CSV files list from Groups folder\n",
        "path = '/content/drive/My Drive/UCSD Machine Learning Engineering Bootcamp/Capstone Project/Groups'\n",
        "csv_files = glob.glob(path + \"/*.csv\")\n",
        "\n",
        "# Read each CSV file into DataFrame, creating a list of dataframes\n",
        "df_list = (pd.read_csv(file) for file in csv_files)\n",
        "\n",
        "# Concatenate all DataFrames\n",
        "clean_df = pd.concat(df_list, ignore_index=True)\n",
        "clean_df = clean_df[['Label', 'Clean_Text', 'Full_Text']]"
      ],
      "metadata": {
        "id": "AZoxf8OYBCZt"
      },
      "id": "AZoxf8OYBCZt",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5df9453c",
      "metadata": {
        "id": "5df9453c"
      },
      "outputs": [],
      "source": [
        " # Show a sample email\n",
        "clean_df.iloc[1][['Full_Text', 'Clean_Text']].to_dict()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fb016351",
      "metadata": {
        "id": "fb016351"
      },
      "outputs": [],
      "source": [
        "clean_df = clean_df[['Label', 'Clean_Text']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5bfeda7b",
      "metadata": {
        "id": "5bfeda7b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4bea08a5-9fa4-4c57-decd-6bcdf3699763"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Label         0\n",
              "Clean_Text    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "# Check number of missing values\n",
        "clean_df.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a4fb12f5",
      "metadata": {
        "id": "a4fb12f5"
      },
      "outputs": [],
      "source": [
        "# Drop missing values\n",
        "clean_df = clean_df.dropna(axis=0)\n",
        "clean_df = clean_df.reset_index(drop=True)\n",
        "clean_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3d1ef087",
      "metadata": {
        "id": "3d1ef087"
      },
      "outputs": [],
      "source": [
        "# Save to CSV\n",
        "clean_df.to_csv(DATA_PATH + 'CleanData.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d9c16351",
      "metadata": {
        "id": "d9c16351"
      },
      "source": [
        "## Data Exploration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1d09390d",
      "metadata": {
        "id": "1d09390d"
      },
      "outputs": [],
      "source": [
        "clean_df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "491170a7",
      "metadata": {
        "id": "491170a7"
      },
      "source": [
        "### Label Insights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1bce9fb5",
      "metadata": {
        "id": "1bce9fb5"
      },
      "outputs": [],
      "source": [
        "# Check for balanced data\n",
        "clean_df.label.value_counts().plot.pie(autopct='%1.1f%%',shadow=True,explode=[0.1,0.1])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "caa94e23",
      "metadata": {
        "id": "caa94e23"
      },
      "source": [
        "### Text Insights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "59cd4e2c",
      "metadata": {
        "id": "59cd4e2c",
        "outputId": "e43cc408-1fab-484b-a9c3-f800beda76b0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(count                                    39206\n",
              " unique                                   28256\n",
              " top       schedule crawler : hourahead failure\n",
              " freq                                       185\n",
              " Name: Subject, dtype: object,\n",
              " count                          39142\n",
              " unique                         35412\n",
              " top       click here to be removed\\n\n",
              " freq                              65\n",
              " Name: Message, dtype: object)"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Quick summary\n",
        "clean_df['Clean_Text'].describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "22a5a53b",
      "metadata": {
        "id": "22a5a53b",
        "outputId": "78a092ae-1c73-4b06-a83e-bca64790e097"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Label      0\n",
              "Email    627\n",
              "dtype: int64"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Graph of email word length\n",
        "clean_df['Length'] = clean_df['Clean_Text'].apply(len)\n",
        "clean_df['Length'].plot(bins=50, kind='hist',figsize=(10,7))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8d3b7d06",
      "metadata": {
        "id": "8d3b7d06",
        "outputId": "7dfdf318-9117-46a7-e79d-7996a5a7627a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Label</th>\n",
              "      <th>Email</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>650</th>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1349</th>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2226</th>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2353</th>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3331</th>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38630</th>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38632</th>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38695</th>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38723</th>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38952</th>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>627 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       Label Email\n",
              "650      0.0   NaN\n",
              "1349     0.0   NaN\n",
              "2226     0.0   NaN\n",
              "2353     0.0   NaN\n",
              "3331     0.0   NaN\n",
              "...      ...   ...\n",
              "38630    1.0   NaN\n",
              "38632    1.0   NaN\n",
              "38695    1.0   NaN\n",
              "38723    1.0   NaN\n",
              "38952    1.0   NaN\n",
              "\n",
              "[627 rows x 2 columns]"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "clean_df.hist(column='Length', by='Label', bins=50, figsize=(15,8))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "from matplotlib import pyplot as plt"
      ],
      "metadata": {
        "id": "PL7K7lYWHCKD"
      },
      "id": "PL7K7lYWHCKD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mx_UYPD3DDB-"
      },
      "id": "mx_UYPD3DDB-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "-name identification\n",
        "-word picture\n",
        "-most frequent words\n",
        "-number of urls/numbers"
      ],
      "metadata": {
        "id": "QK5sMSxDDGIv"
      },
      "id": "QK5sMSxDDGIv"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}